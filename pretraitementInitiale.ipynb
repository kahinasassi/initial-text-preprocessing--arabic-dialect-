{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pretraitementInitiale.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kahinasassi/initial-text-preprocessing--arabic-dialect-/blob/master/pretraitementInitiale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eay3p0ooqLwd"
      },
      "source": [
        "# Auteur: SASSI KAHINA \"ISII\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EZ5633wqjtA"
      },
      "source": [
        "## *le fichier regroupe les traitements appliqué dans la phase de prétraitement initaile*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpHpKmsEfSiZ",
        "outputId": "13ca5b29-197e-4ceb-dcf4-cfcbe82744c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk import re\n",
        "from nltk import defaultdict\n",
        "import io\n",
        "from nltk import  word_tokenize\n",
        "from nltk import  sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import codecs\n",
        "import csv\n",
        "import pickle\n",
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB,ComplementNB\n",
        "from sklearn import metrics\n",
        "from gensim.parsing.preprocessing import strip_short\n",
        "import nltk\n",
        "import phonetics\n",
        "from nltk.probability import ConditionalFreqDist\n",
        "\n",
        "from itertools import groupby\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpS6gxEMfk2h"
      },
      "source": [
        "#vérifie si l'encodage est utf_8\n",
        "def check_utf8(filename): \n",
        "        try:\n",
        "            f = codecs.open(filename, encoding='utf-8', errors='strict')\n",
        "            for line in f:\n",
        "                pass\n",
        "            return 1 #valid utf_8\n",
        "        except UnicodeDecodeError:\n",
        "            return 0 #invalid utf_8\n",
        "\n",
        "# ouvrir un fichier text\n",
        "def open_txt_file(chemin):\n",
        "    #open text file atfter checking if its utf_8  encoding    \n",
        "    check=check_utf8(chemin)\n",
        "    if(check == 1):\n",
        "        f = io.open(chemin,'r',encoding='utf8')\n",
        "    elif(check == 0):\n",
        "        f = io.open(chemin,'r')\n",
        "    return f.read()\n",
        "\n",
        "# convertir un text vers une liste\n",
        "def text_to_list(chemin):\n",
        "    text=open_txt_file(chemin)\n",
        "    liste=[]\n",
        "    liste=text.split(\"\\n\")\n",
        "    return liste\n",
        "\n",
        "# ouvrir un fichier pickle\n",
        "def open_pickle(path):\n",
        "  with open(path, 'rb') as handle: \n",
        "    doc= pickle.load(handle)\n",
        "    return doc\n",
        "\n",
        "def save_pickle(variable,filename):\n",
        "    with open(filename, 'wb') as handle:\n",
        "         pickle.dump(variable, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def is_arabizi(word):\n",
        "  if len(re.findall(r'^[a-zA-Z0-9]+$',word)) > 0:\n",
        "    return 1\n",
        "  else: \n",
        "    return 0\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbGbygdAfvHu",
        "outputId": "bc137452-0f3e-48d0-f387-0599acf2c375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAlR81lHiTBo"
      },
      "source": [
        "#Suppression des urls , hachtags et tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VevRD7eqiPWq"
      },
      "source": [
        "# TRAITEMENT 1\n",
        "\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "\n",
        "def remove_URL(text):\n",
        "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
        "    return url.sub(r\"\", text)\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "def remove_tags(text):\n",
        "  return re.sub(r\"@(\\w+|_|\\.)*\", ' ', text, flags=re.MULTILINE)\n",
        "  \n",
        "\n",
        "def remove_hashtag(text):\n",
        "  return re.sub(r\"#(\\w+|_)*\", ' ', text, flags=re.MULTILINE)\n",
        " \n",
        "\n",
        "def remove_html(text):\n",
        "    html = re.compile(r\"<.*?>\")\n",
        "    return html.sub(r\"\", text)\n",
        "\n",
        "def remove_punct(text):\n",
        "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
        "    return text.translate(table)\n",
        "\n",
        "from gensim.parsing.preprocessing import strip_punctuation\n",
        "from gensim.parsing.preprocessing import strip_numeric\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBvoW4_eiwE1"
      },
      "source": [
        "# suppression des lettre répérté"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7cfv-llVym9"
      },
      "source": [
        "#charger les deux doctionnaires, francais et anglais pour faire la détection de la langue avant la traduction\n",
        "dictionnaire_francais=open_pickle(\"/content/drive/My Drive/PROJET FIN ETUDE 2019 2020/ressources/lexique/lexique_fr.pickle\")\n",
        "dictionnaire_anglais=open_pickle(\"/content/drive/My Drive/PROJET FIN ETUDE 2019 2020/ressources/lexique/lexique_eng.pickle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0WZOcQyV2A7"
      },
      "source": [
        "def detect_fr(word): #reçoit le mot, retourne vrai s'il est francais, faux sinon\n",
        "    word_min=word.lower()\n",
        "    if word_min in dictionnaire_francais:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def detect_en(word): #reçoit le mot, retourne vrai s'il est anglais, faux sinon\n",
        "    word_min=word.lower()\n",
        "    if word_min in dictionnaire_anglais:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0_7wU9gBDRp"
      },
      "source": [
        "#Convertion en miniscule + Suppression les lettres répérés\n",
        "def remove_repeating_char(text):\n",
        "  lower_word=text.lower()\n",
        "  liste=tokenization(lower_word)\n",
        "  sentence=''\n",
        "  for word in liste:\n",
        "    if(detect_en(word) == False):\n",
        "      if(sentence == ''):\n",
        "        new=''.join(c for c, _ in groupby(word))# supprime les caractères répété dans un mots(group by retourne une seul occurance de chaque lettre dans le mot)\n",
        "        sentence=sentence+''+new\n",
        "      else:\n",
        "        new=''.join(c for c, _ in groupby(word))\n",
        "        sentence=sentence+' '+new\n",
        "    else: # si le mot est anglais ie detecté dans le dictionnaire( good) le mot ne sera traité comme mot originale\n",
        "      if(sentence == ''):\n",
        "        sentence=sentence+word\n",
        "      else:\n",
        "        sentence=sentence+' '+word\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54sDYfKQi-7_"
      },
      "source": [
        "#Suppression de la ponctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXYPbcPGi609"
      },
      "source": [
        "def remove_ponctuation(text):\n",
        "   puncts = [',', '.', '\"', ':', ')', '(', '-', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '£', \n",
        " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
        " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
        " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
        " '∙', '）', '↓', '、', '│','!','?', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗',' ️�','▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
        "   \n",
        "   x = str(text)\n",
        "   for punct in puncts:\n",
        "      if punct in x:\n",
        "          x = x.replace(punct, f' ')\n",
        "   return x\n",
        "def remove_punct(text):\n",
        "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
        "    return text.translate(table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLF6uvf7jEtZ"
      },
      "source": [
        "#Suppression des imojis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77FxLP7cjLhO",
        "outputId": "cd3576d4-d187-45b7-ab02-8c0e686488d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        \"]+\",\n",
        "        flags=re.UNICODE,\n",
        "    )\n",
        "    return emoji_pattern.sub(r\"\", string)\n",
        "print(remove_emoji(\"woman with dignity nombre human heart �☝✊\"))\n",
        "#----------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "#load la liste des emojis a partir de facebook\n",
        "liste_emoji=text_to_list(\"/content/drive/My Drive/PROJET FIN ETUDE 2019 2020/ressources/all_emojis.txt\")\n",
        "\n",
        "# la suppression\n",
        "\n",
        "def remove_imogi(text):  \n",
        "   x = str(text)\n",
        "   for punct in liste_emoji:\n",
        "      if punct in x:\n",
        "          x = x.replace(punct, f'')\n",
        "   return x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "woman with dignity nombre human heart \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVKiI_2Sw1aB"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "def naive_bayes(data):\n",
        "  # Set up training and test sets by choosing random samples from classes\n",
        "  X_train, X_test, y_train, y_test = train_test_split(data['text'].values, data['label'].values, test_size=0.20, random_state=0)\n",
        "  model = MultinomialNB()\n",
        "  vect = CountVectorizer()\n",
        "  vect.fit_transform(data['text'].values)  #train the vectorizer, build the vocablury\n",
        "  tfidf_transformer=TfidfTransformer()\n",
        "  X_train_tfidf=vect.transform(X_train)\n",
        "  X_test_vect=vect.transform(X_test)\n",
        "  model.fit(X_train_tfidf,y_train)\n",
        "  model.score(X_train_tfidf,y_train)\n",
        "  y_pred = model.predict(X_test_vect)\n",
        "  y_pred\n",
        "  from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "  print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))\n",
        "  print(\"\\nCOnfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0vjYV_Nj-vM"
      },
      "source": [
        "#suppression des chiffres isolé"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i69j5HyJjk8b"
      },
      "source": [
        "def remove_numbers(text):\n",
        "  return  re.sub(r\"\\b[0-9]+\\b\", \" \",text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IBb_Y1wPSGK"
      },
      "source": [
        "# suppression des mots court"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV2eTS4_kEhp"
      },
      "source": [
        "def remove_short(text):\n",
        "  lower_word=text.lower()\n",
        "  liste=tokenization(lower_word)\n",
        "  sentence=''\n",
        "  for word in liste:\n",
        "    if(len(word) == 1):\n",
        "        new=''\n",
        "        sentence=sentence+''+new\n",
        "    else:\n",
        "      if(sentence == ''):\n",
        "        new=word\n",
        "        sentence=sentence+''+new\n",
        "      else:\n",
        "        new=word\n",
        "        sentence=sentence+' '+new\n",
        "      \n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zU9tPcQkhHb"
      },
      "source": [
        "tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGiPsEhBkZom"
      },
      "source": [
        "def tokenization(text):\n",
        "    return word_tokenize(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4L9p0eok05j"
      },
      "source": [
        "#*Execution* et evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD9N5WDgYBLQ",
        "outputId": "6a05d189-7ed0-4653-cee0-0c8212b3dbd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "data=open_pickle(\"/content/drive/My Drive/PROJET FIN ETUDE 2019 2020/ressources/donnefusioner.pickle\")\n",
        "#Suppression des instances doublons\n",
        "data=data.drop_duplicates()\n",
        "print(len(data))\n",
        "\n",
        "#supression nan\n",
        "data.isnull().sum()\n",
        "data=data.dropna(how='any')\n",
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n25pERXdenh",
        "outputId": "52b8a182-e0d8-4676-ab17-cb5c3cdca933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "data.info()\n",
        "print('**********************************************************************')\n",
        "print(data.shape)\n",
        "print('**********************************************************************')\n",
        "#print(data.label.value_counts())\n",
        "print(\"nbr de val positives = \",len(data.loc[data['label'] == 1].iloc[:,1]))\n",
        "print(\"nbr de val negatives = \",len(data.loc[data['label'] == -1].iloc[:,1]))\n",
        "print(\"nbr de val neutres = \",len(data.loc[data['label'] == 0].iloc[:,1]))\n",
        "print(\"**********************************************************************\")\n",
        "print(\"les valeurs nuls:\\n\", data.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 21023 entries, 0 to 22021\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   text    21023 non-null  object \n",
            " 1   label   21023 non-null  float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 492.7+ KB\n",
            "**********************************************************************\n",
            "(21023, 2)\n",
            "**********************************************************************\n",
            "nbr de val positives =  8504\n",
            "nbr de val negatives =  4632\n",
            "nbr de val neutres =  7877\n",
            "**********************************************************************\n",
            "les valeurs nuls:\n",
            " text     0\n",
            "label    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPyM_j5BYOiW"
      },
      "source": [
        "# Avant le prétraitement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZRyU41HgypD",
        "outputId": "d91774e1-9938-4478-b09b-233b4aca5dcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "for indice  in list(data.index.values): \n",
        "    text=str(data['text'][indice])\n",
        "    data['text'][indice]=text\n",
        "naive_bayes(data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 66.56%\n",
            "\n",
            "COnfusion Matrix:\n",
            " [[ 538  238  160    0]\n",
            " [ 191  982  427    0]\n",
            " [ 225  164 1279    0]\n",
            " [   0    1    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIW_osFNTSUb"
      },
      "source": [
        "#suppression des urls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lV8AwlrdDpT",
        "outputId": "86491dfc-0515-4f3b-9319-6434cd9a67f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "for indice  in list(data.index.values): \n",
        "    text=str(data['text'][indice])\n",
        "    text=remove_URL(text) \n",
        "    data['text'][indice]=text\n",
        "naive_bayes(data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 66.54%\n",
            "\n",
            "COnfusion Matrix:\n",
            " [[ 537  239  160    0]\n",
            " [ 191  981  428    0]\n",
            " [ 225  163 1280    0]\n",
            " [   0    1    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFG0MV0YTWIP"
      },
      "source": [
        "#suppression des tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlOg5aMClGZ6",
        "outputId": "6bf14f05-5dd3-4bc5-c8d9-61a728609496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "for indice  in list(data.index.values): \n",
        "    text=str(data['text'][indice])\n",
        "    text=remove_tags(text) \n",
        "    data['text'][indice]=text\n",
        "naive_bayes(data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 66.54%\n",
            "\n",
            "COnfusion Matrix:\n",
            " [[ 537  239  160    0]\n",
            " [ 191  981  428    0]\n",
            " [ 225  163 1280    0]\n",
            " [   0    1    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I19dqgdTY52"
      },
      "source": [
        "#suppression des hachtags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HahO1rKolqhq",
        "outputId": "d527d942-590a-45a3-bb6f-09be5896ae85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "for indice  in list(data.index.values): \n",
        "    text=str(data['text'][indice])\n",
        "    text=remove_hashtag(text) \n",
        "    data['text'][indice]=text\n",
        "naive_bayes(data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 66.59%\n",
            "\n",
            "COnfusion Matrix:\n",
            " [[ 538  239  159    0]\n",
            " [ 189  982  429    0]\n",
            " [ 226  162 1280    0]\n",
            " [   0    1    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWh0o9qeTccB"
      },
      "source": [
        "#supression des caractères répétés"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUQUiz63l0Bt",
        "outputId": "7d1e5a9b-313b-46cf-9a54-4c3926359970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "for indice in data.index: \n",
        "    text=str(data['text'][indice])\n",
        "    data['text'][indice]=remove_repeating_char(text)\n",
        "naive_bayes(data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 67.02%\n",
            "\n",
            "COnfusion Matrix:\n",
            " [[ 537  238  161    0]\n",
            " [ 193  985  422    0]\n",
            " [ 205  167 1296    0]\n",
            " [   0    1    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e-rkvYETgoN"
      },
      "source": [
        "#suppression de la ponctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF5czckvyPpw",
        "outputId": "5ab492df-c232-46e5-9f61-367b1d339523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "for indice in data.index: \n",
        "    text=str(data['text'][indice])\n",
        "    data['text'][indice]=remove_punct(text) \n",
        "naive_bayes(data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 67.09%\n",
            "\n",
            "COnfusion Matrix:\n",
            " [[ 534  239  163    0]\n",
            " [ 190  987  423    0]\n",
            " [ 200  168 1300    0]\n",
            " [   0    1    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucMiU-88Tkor"
      },
      "source": [
        "#suppression des mots court"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHR7dQYUmfak",
        "outputId": "adb0fb58-3bf5-4ae3-dbdf-ab643a1ee91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "for indice in data.index: \n",
        "    text=str(data['text'][indice])\n",
        "    data['text'][indice]=remove_short(text)\n",
        "naive_bayes(data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 67.09%\n",
            "\n",
            "COnfusion Matrix:\n",
            " [[ 534  239  163    0]\n",
            " [ 190  987  423    0]\n",
            " [ 200  168 1300    0]\n",
            " [   0    1    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnApXhRHTqTf"
      },
      "source": [
        "#suppression des chiffres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZbJUNcj9omz"
      },
      "source": [
        "for indice in data.index: \n",
        "    text=str(data['text'][indice])\n",
        "    data['text'][indice]=remove_numbers(text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsPqXDXKc_QW"
      },
      "source": [
        "# suppression des imogis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgHTv0PYaNE0",
        "outputId": "04b7f814-9a27-4570-8315-d0883504c67d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "data[\"text\"] = data.text.map(lambda x: remove_emoji(x))\n",
        "\n",
        "naive_bayes(data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 67.04%\n",
            "\n",
            "COnfusion Matrix:\n",
            " [[ 538  225  173    0]\n",
            " [ 194  980  426    0]\n",
            " [ 205  162 1301    0]\n",
            " [   0    1    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYAq2N8-R8yY"
      },
      "source": [
        "#Traitement des abréviation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP2kMcMiSFlP"
      },
      "source": [
        "## 2 remplacement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6465215OSJkn"
      },
      "source": [
        "Le but: identifier le mot abrégé dans un commentaire et le remplacer par sa signification\n",
        "- on verifie chaque mot si est une abréviation\n",
        "- si oui on cherche sa signification dans le fichier\n",
        "- on remplace dans la phrase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upCFbuogRsea"
      },
      "source": [
        "#load la liste des abréviations \n",
        "url=\"/content/drive/My Drive/PROJET FIN ETUDE 2019 2020/ressources/abréviation.csv\"\n",
        "abreviation=pd.read_csv(url)\n",
        "\n",
        "def replace_abrv(texte):\n",
        " word= tokenization(texte) \n",
        " x=str(texte)\n",
        " ma_lis=[]\n",
        " for val in word:\n",
        "   if(len(abreviationne(val))!=0):\n",
        "     for indice  in list(abreviation.index.values): \n",
        "       text=str(abreviation['text'][indice])\n",
        "       if(val== text):\n",
        "         tt=str(abreviation['abreviation'][indice])\n",
        "         ma_lis.append(tt)\n",
        "         x = x.replace(val, tt)  \n",
        " return x  \n",
        "\n",
        "\n",
        "#print(replace_abrv(\"hi evry bnjr bn mone\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doP1ukqkXl2-",
        "outputId": "516aa24f-8dea-4084-e65e-76e0b1c04325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "for indice  in list(data.index.values): \n",
        "    text=str(data['text'][indice])   \n",
        "    text=replace_abrv(text) \n",
        "    data['text'][indice]=text\n",
        "\n",
        "naive_bayes(data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 67.09%\n",
            "\n",
            "COnfusion Matrix:\n",
            " [[ 536  237  163    0]\n",
            " [ 190  985  425    0]\n",
            " [ 201  167 1300    0]\n",
            " [   0    1    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWtfkP6MnInL"
      },
      "source": [
        "save_pickle(data,\"/content/drive/My Drive/PROJET FIN ETUDE 2019 2020/dataset finale/Donné trouvé/data_pré_init.pickle\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M_q66C0nLoI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}